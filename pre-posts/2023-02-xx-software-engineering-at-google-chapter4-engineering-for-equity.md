---
title: 'Software Engineering at Google: Chapter 4 - Engineering for Equity'
date: '2023-02-14'
---

> Bias Is the Default

こういう節があるのは、現状認識としてとてもよい。

> In 2015, software engineer Jacky Alciné pointed out that the image recognition algorithms in Google Photos were classifying his black friends as “gorillas.” 

これを Google の本が書いているのは素晴らしい。 

> As late as 2018, Google still had not adequately addressed the underlying problem.

これもすごい (gorillas の件から続いている)。

> One way to address these problems is to help the software engineering organization itself look like the populations for whom we build products.
> 
> これらの問題を解決する一つの方法は、ソフトウェアエンジニアリングの組織そのものを、製品を作る人々のように見せることです。

これには疑問符がつくぞ。

> We cannot expect the output to be valid if both the training data and those creating the software represent only a small subsection of people. 
> 
> 学習データも、ソフトウェアを作る人も、一部の人たちだけでは、アウトプットの有効性は期待できない。

ソフトウェア作る人は関係なくない? (これは AI 文脈の話)

> It begins with more comprehensive user-experience research. This research should be done with user groups that are multilingual and multicultural and that span multiple countries, socioeconomic class, abilities, and age ranges.
> 
> それは、より包括的なユーザー・エクスペリエンス調査から始まります。この調査は、多言語・多文化で、複数の国、社会経済階級、能力、年齢層にまたがるユーザーグループに対して行われるべきものです。

そうですね。

TODO: Challenge Established Processes から先 
